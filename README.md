
This is a simple tutorial for Streamlit and Ollama, toying with agentic
applications.

It requires Ollama and llama3.1, but is otherwise just a tool to "create" your own LLM agents for simple conversations (that have no memory/context).

There is not significant extensibility here to RAG, but it was fun
